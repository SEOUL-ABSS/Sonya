{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOurAZFllfnvlnLvXixNuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOUL-ABSS/Sonya/blob/main/TEST2_YEEP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfDWQhVL58E6"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Colab에서 실행하는 배 소음 탐지 통합 노트북\n",
        "# - 사내망 환경 (TF 2.12, Python 3.10)에 맞춰 버전 고정\n",
        "# - 오프라인 사용을 위한 모든 자원 다운로드 및 패키징 포함\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1. 환경 설정: 필요한 라이브러리 설치\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"1. 환경 설정 시작: 필요한 라이브러리 설치 중...\")\n",
        "\n",
        "# TensorFlow 2.12.0을 포함한 모든 라이브러리를 정확한 버전으로 설치\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install tensorflow-hub==0.16.1\n",
        "!pip install librosa==0.10.1\n",
        "!pip install soundfile==0.12.1\n",
        "!pip install numpy==1.24.4\n",
        "!pip install pandas==2.2.2\n",
        "!pip install scikit-learn==1.5.0\n",
        "!pip install matplotlib==3.9.0\n",
        "!pip install seaborn==0.13.2\n",
        "\n",
        "print(\"\\n라이브러리 설치 완료. 런타임 재시작이 필요할 수 있습니다.\")\n",
        "print(\"설치된 TensorFlow 버전 확인:\", tf.__version__)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2. 자원 다운로드\n",
        "# ------------------------------------------------------------------------------\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"\\n2. 자원 다운로드 시작...\")\n",
        "\n",
        "# DeepShip 데이터셋 클론\n",
        "if not os.path.exists('/content/DeepShip'):\n",
        "    !git clone https://github.com/irfankamboh/DeepShip.git\n",
        "    print(\"DeepShip 데이터셋 클론 완료.\")\n",
        "else:\n",
        "    print(\"DeepShip 데이터셋이 이미 존재합니다.\")\n",
        "\n",
        "# YAMNet 모델 다운로드\n",
        "# Colab은 자동으로 /tmp/tfhub_modules에 캐시하므로 경로 설정이 필요 없음\n",
        "try:\n",
        "    print(\"YAMNet 모델 다운로드 중 (Colab 캐시 사용)...\")\n",
        "    yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "    yamnet_model = hub.load(yamnet_model_handle)\n",
        "    YAMNET_SAMPLE_RATE = 16000\n",
        "    YAMNET_EMBEDDING_DIM = 1024\n",
        "    print(\"YAMNet 모델 다운로드 완료.\")\n",
        "except Exception as e:\n",
        "    print(f\"오류: YAMNet 모델 다운로드 중 오류 발생: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3. 학습 예제 실행 (이전 코드와 동일한 로직)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n3. 학습 예제 실행 시작...\")\n",
        "\n",
        "DEEPSHIP_ACOUSTIC_DATA_PATH = '/content/DeepShip/Acoustic_data'\n",
        "\n",
        "def preprocess_audio_for_yamnet(audio_path, yamnet_model, target_sample_rate=YAMNET_SAMPLE_RATE):\n",
        "    try:\n",
        "        waveform, sr = sf.read(audio_path, dtype='float32')\n",
        "        if sr != target_sample_rate:\n",
        "            waveform = librosa.resample(y=waveform, orig_sr=sr, target_sr=target_sample_rate)\n",
        "        if waveform.ndim > 1:\n",
        "            waveform = np.mean(waveform, axis=1)\n",
        "        scores, embeddings, spectrogram = yamnet_model(tf.constant(waveform, dtype=tf.float32))\n",
        "        mean_embedding = tf.reduce_mean(embeddings, axis=0)\n",
        "        return mean_embedding.numpy()\n",
        "    except Exception as e:\n",
        "        print(f\"오디오 파일 처리 중 오류 발생: {audio_path}, 오류: {e}\")\n",
        "        return None\n",
        "\n",
        "all_audio_paths = []\n",
        "all_labels = []\n",
        "sub_data_folders = ['Train', 'Test']\n",
        "for sub_folder in sub_data_folders:\n",
        "    current_data_path = os.path.join(DEEPSHIP_ACOUSTIC_DATA_PATH, sub_folder)\n",
        "    if os.path.exists(current_data_path) and os.path.isdir(current_data_path):\n",
        "        for class_name in os.listdir(current_data_path):\n",
        "            class_path = os.path.join(current_data_path, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                for file_name in os.listdir(class_path):\n",
        "                    if file_name.endswith('.wav'):\n",
        "                        audio_path = os.path.join(class_path, file_name)\n",
        "                        all_audio_paths.append(audio_path)\n",
        "                        all_labels.append(class_name)\n",
        "\n",
        "if not all_audio_paths:\n",
        "    print(\"오류: 데이터 파일을 찾을 수 없어 학습을 진행할 수 없습니다. 스크립트를 종료합니다.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(all_labels)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "X_train_paths, X_test_paths, y_train_encoded, y_test_encoded = train_test_split(\n",
        "    all_audio_paths, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels\n",
        ")\n",
        "\n",
        "X_train_embeddings = np.array([preprocess_audio_for_yamnet(p, yamnet_model) for p in X_train_paths if preprocess_audio_for_yamnet(p, yamnet_model) is not None])\n",
        "X_test_embeddings = np.array([preprocess_audio_for_yamnet(p, yamnet_model) for p in X_test_paths if preprocess_audio_for_yamnet(p, yamnet_model) is not None])\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train_encoded, num_classes=num_classes)[:len(X_train_embeddings)]\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test_encoded, num_classes=num_classes)[:len(X_test_embeddings)]\n",
        "\n",
        "model = Model(\n",
        "    inputs=Input(shape=(YAMNET_EMBEDDING_DIM,)),\n",
        "    outputs=Dense(num_classes, activation='softmax')(Dropout(0.5)(Dense(128, activation='relu')(Dropout(0.5)(Dense(256, activation='relu')(Input(shape=(YAMNET_EMBEDDING_DIM,)))))))\n",
        ")\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_embeddings, y_train_one_hot,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_embeddings, y_test_one_hot, verbose=0)\n",
        "print(f\"\\n모델 평가 완료. 테스트 세트 정확도: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 4. 오프라인 사용을 위한 자원 패키징\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n4. 오프라인 사용을 위한 자원 패키징 시작...\")\n",
        "\n",
        "# 최종 ZIP 파일 이름\n",
        "zip_file_name = 'offline_resources.zip'\n",
        "\n",
        "# 패키징을 위한 디렉토리 생성\n",
        "os.makedirs('./offline_resources/python_packages', exist_ok=True)\n",
        "\n",
        "# requirements.txt 파일 생성\n",
        "requirements_content = \"\"\"\n",
        "tensorflow==2.12.0\n",
        "tensorflow-hub==0.16.1\n",
        "librosa==0.10.1\n",
        "soundfile==0.12.1\n",
        "numpy==1.24.4\n",
        "pandas==2.2.2\n",
        "scikit-learn==1.5.0\n",
        "matplotlib==3.9.0\n",
        "seaborn==0.13.2\n",
        "\"\"\"\n",
        "with open('./offline_resources/requirements.txt', 'w') as f:\n",
        "    f.write(requirements_content.strip())\n",
        "\n",
        "# pip download를 이용해 패키지 다운로드\n",
        "!pip download -r ./offline_resources/requirements.txt -d ./offline_resources/python_packages\n",
        "\n",
        "# YAMNet 모델 캐시 폴더 복사\n",
        "yamnet_cache_dir = os.environ.get('TFHUB_CACHE_DIR', '/tmp/tfhub_modules')\n",
        "!cp -r {yamnet_cache_dir} ./offline_resources/yamnet_model\n",
        "\n",
        "# DeepShip 데이터셋 복사\n",
        "!cp -r /content/DeepShip ./offline_resources/DeepShip_dataset\n",
        "\n",
        "# 모든 자원을 ZIP 파일로 압축\n",
        "print(f\"\\n'{zip_file_name}' 파일로 압축 중...\")\n",
        "!zip -r {zip_file_name} ./offline_resources\n",
        "\n",
        "print(\"\\n=====================================================\")\n",
        "print(\"         모든 자원 패키징 완료!\")\n",
        "print(\"=====================================================\")\n",
        "print(f\"'{zip_file_name}' 파일을 로컬로 다운로드하세요.\")\n",
        "print(\"이 파일은 Colab 왼쪽의 파일 탐색기에서 찾을 수 있습니다.\")\n",
        "\n",
        "# Colab에서 다운로드 프롬프트를 띄우는 코드\n",
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    }
  ]
}