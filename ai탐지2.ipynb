{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOUL-ABSS/Sonya/blob/main/ai%ED%83%90%EC%A7%802.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 환경 설정 및 필수 라이브브러리 임포트\n",
        "\n",
        "\n",
        "프로젝트에 필요한 모든 라이브러리를 가져오고, 시각화(Matplotlib)를 위한 한글 폰트 설정 및 전역 변수를 정의합니다."
      ],
      "metadata": {
        "id": "5HECfrV3VX1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. 환경 설정 및 필수 라이브러리 임포트\n",
        "# ==============================================================================\n",
        "print(\"1. 환경 설정 및 라이브러리 임포트 중...\")\n",
        "\n",
        "# --- 필수 라이브러리 임포트 ---\n",
        "!pip install boto3\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager as fm\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"라이브러리 임포트 완료.\")\n",
        "\n",
        "# --- Matplotlib 한글 폰트 설정 ---\n",
        "print(\"\\nMatplotlib 한글 폰트 설정 중...\")\n",
        "try:\n",
        "    !sudo apt-get -qq update\n",
        "    !sudo apt-get -qq install -y fonts-nanum\n",
        "    font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "    if os.path.exists(font_path):\n",
        "        fm.fontManager.addfont(font_path)\n",
        "        plt.rc('font', family='NanumGothic')\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "        print(\"Matplotlib 폰트 설정 완료: NanumGothic\")\n",
        "    else:\n",
        "        print(f\"경고: 폰트 파일 '{font_path}'를 찾을 수 없습니다. 기본 폰트를 사용합니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"Matplotlib 폰트 설정 중 오류 발생: {e}. 기본 폰트를 사용합니다.\")\n",
        "\n",
        "# --- 전역 상수 정의 ---\n",
        "print(\"\\n전역 상수 정의 중...\")\n",
        "YAMNET_SAMPLE_RATE = 16000\n",
        "YAMNET_EMBEDDING_DIM = 1024\n",
        "VGGISH_EMBEDDING_DIM = 128\n",
        "PANNS_EMBEDDING_DIM = YAMNET_EMBEDDING_DIM  # PANNs는 YAMNet을 플레이스홀더로 사용\n",
        "\n",
        "# 데이터셋 경로\n",
        "DEEPSHIP_BASE_PATH = '/content/DeepShip'\n",
        "MBARI_NOISE_BASE_DIR = '/content/MBARI_noise_data'\n",
        "\n",
        "# 처리할 모델 목록\n",
        "MODELS_TO_PROCESS = ['YAMNet', 'PANNs', 'VGGish']\n",
        "\n",
        "print(\"전역 상수 정의 완료.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C97YqhrrVWMM",
        "outputId": "c27d4875-bd5e-4ebd-fc61-2793b02361a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 환경 설정 및 라이브러리 임포트 중...\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.40.22-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.41.0,>=1.40.22 (from boto3)\n",
            "  Downloading botocore-1.40.22-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.22->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.22->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.22->boto3) (1.17.0)\n",
            "Downloading boto3-1.40.22-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.22-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.40.22 botocore-1.40.22 jmespath-1.0.1 s3transfer-0.13.1\n",
            "라이브러리 임포트 완료.\n",
            "\n",
            "Matplotlib 한글 폰트 설정 중...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 126371 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Matplotlib 폰트 설정 완료: NanumGothic\n",
            "\n",
            "전역 상수 정의 중...\n",
            "전역 상수 정의 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 데이터셋 준비 (다운로드 및 클론)\n",
        "\n",
        "'ship' 데이터인 DeepShip은 GitHub에서 클론하고, 'noise' 데이터인 MBARI 데이터는 AWS S3에서 다운로드하여 지정된 경로에 준비합니다."
      ],
      "metadata": {
        "id": "asKjLI01VgAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. 데이터셋 준비 (다운로드 및 클론)\n",
        "# ==============================================================================\n",
        "def setup_datasets():\n",
        "    \"\"\"DeepShip 데이터셋을 클론하고 MBARI 노이즈 데이터를 다운로드합니다.\"\"\"\n",
        "    print(\"\\n2. 데이터셋 준비 중...\")\n",
        "\n",
        "    # --- DeepShip 데이터셋 클론 ---\n",
        "    if not os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "        print(f\"DeepShip 데이터셋 클론 중: {DEEPSHIP_BASE_PATH}\")\n",
        "        !git clone -q https://github.com/irfankamboh/DeepShip.git {DEEPSHIP_BASE_PATH}\n",
        "        print(\"DeepShip 데이터셋 클론 완료.\")\n",
        "    else:\n",
        "        print(f\"DeepShip 데이터셋이 이미 존재합니다: {DEEPSHIP_BASE_PATH}\")\n",
        "\n",
        "    # --- MBARI 노이즈 데이터 다운로드 ---\n",
        "    os.makedirs(MBARI_NOISE_BASE_DIR, exist_ok=True)\n",
        "    noise_filename = 'MARS-20180101T000000Z-16kHz.wav'\n",
        "    target_noise_path = os.path.join(MBARI_NOISE_BASE_DIR, noise_filename)\n",
        "\n",
        "    if not Path(target_noise_path).exists():\n",
        "        print(f\"MBARI 노이즈 데이터 다운로드 중: s3://pacific-sound-16khz/2018/01/{noise_filename}\")\n",
        "        try:\n",
        "            s3 = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n",
        "            bucket = s3.Bucket('pacific-sound-16khz')\n",
        "            key = f'2018/01/{noise_filename}'\n",
        "            bucket.download_file(key, target_noise_path)\n",
        "            print(f\"MBARI 노이즈 데이터 다운로드 완료: {target_noise_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"오류: MBARI 데이터 다운로드 실패: {e}\")\n",
        "    else:\n",
        "        print(f\"MBARI 노이즈 데이터가 이미 존재합니다: {target_noise_path}\")\n",
        "\n",
        "# 데이터셋 준비 함수 실행\n",
        "setup_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRNKXfZHVkFM",
        "outputId": "c4ca15c0-6abe-4fa4-b958-42d910cd604a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. 데이터셋 준비 중...\n",
            "DeepShip 데이터셋 클론 중: /content/DeepShip\n",
            "DeepShip 데이터셋 클론 완료.\n",
            "MBARI 노이즈 데이터 다운로드 중: s3://pacific-sound-16khz/2018/01/MARS-20180101T000000Z-16kHz.wav\n",
            "MBARI 노이즈 데이터 다운로드 완료: /content/MBARI_noise_data/MARS-20180101T000000Z-16kHz.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 핵심 기능 함수 정의\n",
        "데이터 로드, 오디오 전처리, 임베딩 추출, 모델 구축, 학습, 평가 등 반복적으로 사용되는 로직들을 기능별 함수로 명확하게 정의합니다."
      ],
      "metadata": {
        "id": "8y9FyQxWVmIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. 핵심 기능 함수 정의\n",
        "# ==============================================================================\n",
        "print(\"\\n3. 핵심 기능 함수 정의 중...\")\n",
        "\n",
        "def load_and_prepare_dataset(deepship_path, noise_data_dir):\n",
        "    \"\"\"DeepShip과 노이즈 데이터를 로드하고 훈련/테스트 세트로 분할합니다.\"\"\"\n",
        "    all_audio_paths, all_labels = [], []\n",
        "\n",
        "    # --- DeepShip('ship') 데이터 로드 ---\n",
        "    deepship_acoustic_path = os.path.join(deepship_path, 'Acoustic_data')\n",
        "    if os.path.exists(deepship_acoustic_path):\n",
        "        print(f\"DeepShip 데이터셋에서 'ship' 오디오 파일 수집 중: {deepship_acoustic_path}\")\n",
        "\n",
        "        # Debugging: Print directory structure (keep for now to confirm fix)\n",
        "        print(\"\\nDeepShip Acoustic_data 디렉토리 구조 확인:\")\n",
        "        try:\n",
        "            for root, dirs, files in os.walk(deepship_acoustic_path):\n",
        "                level = root.replace(deepship_acoustic_path, '').count(os.sep)\n",
        "                indent = ' ' * 4 * (level)\n",
        "                print(f'{indent}{os.path.basename(root)}/')\n",
        "                subindent = ' ' * 4 * (level + 1)\n",
        "                for f in files:\n",
        "                    if f.endswith('.wav'):\n",
        "                        print(f'{subindent}{f}')\n",
        "        except Exception as e:\n",
        "            print(f\"디렉토리 구조 확인 중 오류 발생: {e}\")\n",
        "        print(\"-------------------------------------\\n\")\n",
        "\n",
        "\n",
        "        # Modified logic: Collect .wav files within 'Train' and 'Test' subdirectories\n",
        "        for root, _, files in os.walk(deepship_acoustic_path):\n",
        "            for file in files:\n",
        "                if file.endswith('.wav'):\n",
        "                    full_path = os.path.join(root, file)\n",
        "                    # Check if the file is within a 'Train' or 'Test' subdirectory of Acoustic_data\n",
        "                    relative_path = os.path.relpath(full_path, deepship_acoustic_path)\n",
        "                    path_parts_relative = relative_path.split(os.sep)\n",
        "\n",
        "                    # Simplified logic: Check if the path contains 'Train' or 'Test' and is not directly in Acoustic_data\n",
        "                    if ('Train' in path_parts_relative or 'Test' in path_parts_relative) and len(path_parts_relative) > 1:\n",
        "                         all_audio_paths.append(full_path)\n",
        "                         all_labels.append('ship')\n",
        "                         # print(f\"Found ship audio: {full_path}\") # Uncomment for debugging\n",
        "\n",
        "    else:\n",
        "        print(f\"경고: DeepShip Acoustic_data 경로를 찾을 수 없습니다: {deepship_acoustic_path}\")\n",
        "\n",
        "\n",
        "    # --- MBARI('noise') 데이터 로드 ---\n",
        "    if os.path.exists(noise_data_dir):\n",
        "        print(f\"노이즈 데이터 수집 중: {noise_data_dir}\")\n",
        "        for file in os.listdir(noise_data_dir):\n",
        "            if file.endswith('.wav'):\n",
        "                full_path = os.path.join(noise_data_dir, file)\n",
        "                all_audio_paths.append(full_path)\n",
        "                all_labels.append('noise')\n",
        "                # print(f\"Found noise audio: {full_path}\") # Uncomment for debugging\n",
        "    else:\n",
        "        print(f\"경고: 노이즈 데이터 경로를 찾을 수 없습니다: {noise_data_dir}\")\n",
        "\n",
        "    if not all_audio_paths or len(np.unique(all_labels)) < 2:\n",
        "        print(f\"\\n오류: 'ship'과 'noise' 클래스 모두에 대한 데이터가 부족합니다. 총 샘플 수: {len(all_audio_paths)}, 클래스 수: {len(np.unique(all_labels)) if all_labels else 0}. 처리를 중단합니다.\")\n",
        "        return [], [], [], [], None, False, 0\n",
        "\n",
        "    print(f\"\\n데이터 수집 완료. 총 샘 샘플 수: {len(all_audio_paths)}\")\n",
        "    print(f\"클래스 분포: {pd.Series(all_labels).value_counts().to_dict()}\")\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(all_labels)\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "\n",
        "    X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
        "        all_audio_paths, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels\n",
        "    )\n",
        "    print(f\"데이터 분할 완료. 훈련: {len(X_train_paths)}, 테스트: {len(X_test_paths)}\")\n",
        "    return X_train_paths, X_test_paths, y_train, y_test, label_encoder, True, num_classes\n",
        "\n",
        "def load_audio_models():\n",
        "    \"\"\"TensorFlow Hub에서 오디오 모델들을 로드합니다.\"\"\"\n",
        "    models = {}\n",
        "    handles = {\n",
        "        'YAMNet': 'https://tfhub.dev/google/yamnet/1',\n",
        "        'PANNs': 'https://tfhub.dev/google/yamnet/1',  # Placeholder\n",
        "        'VGGish': 'https://tfhub.dev/google/vggish/1'\n",
        "    }\n",
        "    for name, handle in handles.items():\n",
        "        try:\n",
        "            print(f\"  {name} 모델 로드 중...\")\n",
        "            models[name] = hub.load(handle)\n",
        "        except Exception as e:\n",
        "            print(f\"  오류: {name} 모델 로드 실패: {e}\")\n",
        "            models[name] = None\n",
        "    return models\n",
        "\n",
        "def extract_embeddings(paths, labels, model_name, model_object):\n",
        "    \"\"\"주어진 오디오 경로 목록에서 임베딩을 추출합니다.\"\"\"\n",
        "    embeddings, filtered_labels = [], []\n",
        "\n",
        "    def _get_embedding(path, model):\n",
        "        try:\n",
        "            waveform, sr = sf.read(path, dtype='float32')\n",
        "            if sr != YAMNET_SAMPLE_RATE:\n",
        "                waveform = librosa.resample(y=waveform, orig_sr=sr, target_sr=YAMNET_SAMPLE_RATE)\n",
        "            if waveform.ndim > 1:\n",
        "                waveform = np.mean(waveform, axis=1)\n",
        "\n",
        "            if model_name == 'VGGish':\n",
        "                return np.mean(model(tf.constant(waveform, dtype=tf.float32)), axis=0)\n",
        "            else: # YAMNet and PANNs (placeholder)\n",
        "                _, embedding, _ = model(tf.constant(waveform, dtype=tf.float32))\n",
        "                return np.mean(embedding, axis=0)\n",
        "        except Exception as e:\n",
        "            print(f\"    오류: {path} 임베딩 추출 실패: {e}\")\n",
        "            return None\n",
        "\n",
        "    for i, path in enumerate(paths):\n",
        "        embedding = _get_embedding(path, model_object)\n",
        "        if embedding is not None:\n",
        "            embeddings.append(embedding.numpy())\n",
        "            filtered_labels.append(labels[i])\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"    {i+1}/{len(paths)} 파일 처리 완료.\")\n",
        "\n",
        "    return np.array(embeddings), np.array(filtered_labels)\n",
        "\n",
        "def build_classifier(embedding_dim, num_classes):\n",
        "    \"\"\"분류 헤드 모델을 구축합니다.\"\"\"\n",
        "    input_layer = Input(shape=(embedding_dim,))\n",
        "    x = Dense(128, activation='relu')(input_layer)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def evaluate_and_visualize(model_name, model, history, X_test, y_test, y_test_filtered, label_encoder):\n",
        "    \"\"\"모델 성능을 평가하고 결과를 시각화합니다.\"\"\"\n",
        "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\n--- {model_name} 모델 평가 결과 ---\")\n",
        "    print(f\"  테스트 손실: {loss:.4f}\")\n",
        "    print(f\"  테스트 정확도: {accuracy:.4f}\")\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "    print(\"\\n  분류 리포트:\")\n",
        "    print(classification_report(y_test_filtered, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    cm = confusion_matrix(y_test_filtered, y_pred)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "    plt.title(f'{model_name} 혼동 행렬')\n",
        "    plt.xlabel('예측 레이블')\n",
        "    plt.ylabel('실제 레이블')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='훈련 정확도')\n",
        "    plt.plot(history.history['val_accuracy'], label='검증 정확도')\n",
        "    plt.title(f'{model_name} 훈련 및 검증 정확도')\n",
        "    plt.xlabel('에폭'); plt.ylabel('정확도'); plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='훈련 손실')\n",
        "    plt.plot(history.history['val_loss'], label='검증 손실')\n",
        "    plt.title(f'{model_name} 훈련 및 검증 손실')\n",
        "    plt.xlabel('에폭'); plt.ylabel('손실'); plt.legend()\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "print(\"핵심 기능 함수 정의 완료.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFaLKtJEVloz",
        "outputId": "9d43a77d-d1b2-40d3-c111-3aae47065c09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. 핵심 기능 함수 정의 중...\n",
            "핵심 기능 함수 정의 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 메인 실행 파이프라인\n",
        "\n",
        "\n",
        "정의된 함수들을 순서대로 호출하여 전체 데이터 처리, 모델 학습 및 평가 파이프라인을 실행합니다. 이 셀 하나만 실행하면 모든 과정이 진행됩니다."
      ],
      "metadata": {
        "id": "EXXe93TLVqSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. 메인 실행 파이프라인\n",
        "# ==============================================================================\n",
        "print(\"\\n4. 메인 파이프라인 실행 시작...\")\n",
        "\n",
        "# --- 데이터 로드 및 준비 ---\n",
        "X_train_paths, X_test_paths, y_train_enc, y_test_enc, label_encoder, is_data_prepared, num_classes = \\\n",
        "    load_and_prepare_dataset(DEEPSHIP_BASE_PATH, MBARI_NOISE_BASE_DIR)\n",
        "\n",
        "if is_data_prepared:\n",
        "    # --- 오디오 모델 로드 ---\n",
        "    audio_models = load_audio_models()\n",
        "\n",
        "    final_results = {}\n",
        "\n",
        "    # --- 모델별 임베딩 추출, 학습, 평가 ---\n",
        "    for model_name in MODELS_TO_PROCESS:\n",
        "        model_object = audio_models.get(model_name)\n",
        "        if model_object is None:\n",
        "            print(f\"\\n--- {model_name} 모델을 로드할 수 없어 건너뜁니다. ---\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n--- {model_name} 처리 시작 ---\")\n",
        "\n",
        "        # 임베딩 추출\n",
        "        print(f\"  {model_name} 훈련 데이터 임베딩 추출 중...\")\n",
        "        X_train_emb, y_train_filtered = extract_embeddings(X_train_paths, y_train_enc, model_name, model_object)\n",
        "\n",
        "        print(f\"  {model_name} 테스트 데이터 임베딩 추출 중...\")\n",
        "        X_test_emb, y_test_filtered = extract_embeddings(X_test_paths, y_test_enc, model_name, model_object)\n",
        "\n",
        "        if X_train_emb.size == 0 or X_test_emb.size == 0:\n",
        "            print(f\"  오류: {model_name} 임베딩 추출에 실패하여 학습을 건너뜁니다.\")\n",
        "            continue\n",
        "\n",
        "        # 레이블 One-Hot 인코딩\n",
        "        y_train_one_hot = tf.keras.utils.to_categorical(y_train_filtered, num_classes=num_classes)\n",
        "        y_test_one_hot = tf.keras.utils.to_categorical(y_test_filtered, num_classes=num_classes)\n",
        "\n",
        "        # 분류기 구축\n",
        "        embedding_dim = X_train_emb.shape[1]\n",
        "        classifier = build_classifier(embedding_dim, num_classes)\n",
        "\n",
        "        # 모델 학습\n",
        "        history = classifier.fit(\n",
        "            X_train_emb, y_train_one_hot,\n",
        "            validation_data=(X_test_emb, y_test_one_hot),\n",
        "            epochs=50,\n",
        "            batch_size=32,\n",
        "            callbacks=[\n",
        "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "            ],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # 모델 평가 및 시각화\n",
        "        evaluate_and_visualize(model_name, classifier, history, X_test_emb, y_test_one_hot, y_test_filtered, label_encoder)\n",
        "\n",
        "        # 최종 결과 저장\n",
        "        _, accuracy = classifier.evaluate(X_test_emb, y_test_one_hot, verbose=0)\n",
        "        final_results[model_name] = accuracy\n",
        "\n",
        "    # --- 최종 성능 요약 ---\n",
        "    print(\"\\n--- 최종 모델 성능 비교 ---\")\n",
        "    if final_results:\n",
        "        for model_name, acc in sorted(final_results.items(), key=lambda item: item[1], reverse=True):\n",
        "            print(f\"  - {model_name}: Test Accuracy = {acc:.4f}\")\n",
        "    else:\n",
        "        print(\"  평가된 모델이 없습니다.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n데이터 준비에 실패하여 모델 학습 및 평가를 진행하지 않았습니다.\")\n",
        "\n",
        "print(\"\\n모든 파이프라인 실행 완료.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3k2ukPyVtR0",
        "outputId": "841af1f9-8e10-4a09-c848-a2387216a39c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. 메인 파이프라인 실행 시작...\n",
            "경고: DeepShip Acoustic_data 경로를 찾을 수 없습니다: /content/DeepShip/Acoustic_data\n",
            "노이즈 데이터 수집 중: /content/MBARI_noise_data\n",
            "\n",
            "오류: 'ship'과 'noise' 클래스 모두에 대한 데이터가 부족합니다. 총 샘플 수: 1, 클래스 수: 1. 처리를 중단합니다.\n",
            "\n",
            "데이터 준비에 실패하여 모델 학습 및 평가를 진행하지 않았습니다.\n",
            "\n",
            "모든 파이프라인 실행 완료.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colab 시작하기",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}